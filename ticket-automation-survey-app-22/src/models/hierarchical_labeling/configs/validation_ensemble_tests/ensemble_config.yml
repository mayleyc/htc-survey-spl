PRETRAINED_LM: bert-base-uncased
MODEL_L1: "src/models/hierarchical_labeling/dumps/bert_l1" # path to dump file
MODEL_L2: "src/models/hierarchical_labeling/dumps/bert_test_24__/epoch_3/model.pt"

L2_REG: 0.01
LEARNING_RATE: 2.0e-5 # 5.0e-6 1.0e-5 5.0e-5
BATCH_SIZE: 8
TEST_BATCH_SIZE: 8
EPOCHS: 3
CLASS_BALANCED_WEIGHTED_LOSS: false
LABEL: "flattened_label" # Which label to use for classification: "label", "flattened_label"
REMOVE_GARBAGE_TEXT: false

DEVICE: "cuda"
TENSORBOARD: false

MODEL_FOLDER: "src/models/hierarchical_labeling/dumps/ens_to_remove"
EPOCHS_TO_KEEP: 2
SAVE_NON_IMPROVING: false  # Always save all epochs. True also saves non-improving
EARLY_STOPPING:
  monitor_key: "loss"
  patience: 3
  delta: 0.0001
  metrics_trend: "decreasing" # The desired tendency of the metric

# Reload
RELOAD: false
PATH_TO_RELOAD: "" # Full path to the model folder (e.g. dump_model) or to the epoch folder

NUM_FOLD: 3
CV_REPEAT: 2